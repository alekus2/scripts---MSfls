import pandas as pd
import os
import re

class OtimizadorIFQ6:
    def validacao(self, paths, colunas_codigos):
        # Colunas esperadas
        nomes_colunas = [
            "CD_PROJETO", "CD_TALHAO", "NM_PARCELA", "DC_TIPO_PARCELA",
            "NM_AREA_PARCELA", "NM_LARG_PARCELA", "NM_COMP_PARCELA",
            "NM_DEC_LAR_PARCELA", "NM_DEC_COM_PARCELA", "DT_INICIAL",
            "DT_FINAL", "CD_EQUIPE", "NM_LATITUDE", "NM_LONGITUDE",
            "NM_ALTITUDE", "DC_MATERIAL", "NM_FILA", "NM_COVA",
            "NM_FUSTE", "NM_DAP_ANT", "NM_ALTURA_ANT", "NM_CAP_DAP1",
            "NM_DAP2", "NM_DAP", "NM_ALTURA", "CD_01", "CD_02", "CD_03"
        ]
        
        # Códigos válidos para verificação extra
        codigos_validos = [chr(i) for i in range(ord('A'), ord('X'))]
        
        lista_df = []  # Lista para acumular os DataFrames processados
        
        for path in paths:
            if not os.path.exists(path):
                print(f"Erro: O arquivo '{path}' não foi encontrado.")
                continue
            print(f"Processando o arquivo: {path}")
            
            df = pd.read_excel(path)
            # Converte os nomes das colunas para maiúsculo
            df.columns = [col.upper() for col in df.columns]
            
            # Verifica se todas as colunas esperadas estão presentes
            colunas_faltando = [col for col in nomes_colunas if col not in df.columns]
            if colunas_faltando:
                print(f"Erro: As colunas esperadas não foram encontradas no arquivo '{path}': {', '.join(colunas_faltando)}")
                continue
            
            # Adiciona as colunas de códigos extras, se existirem
            colunas_a_manter = nomes_colunas.copy()
            for coluna_codigos in colunas_codigos:
                coluna_codigos = coluna_codigos.upper()
                if coluna_codigos in df.columns:
                    codigos_encontrados = df[coluna_codigos].astype(str).str.upper().isin(codigos_validos)
                    if codigos_encontrados.any():
                        print(f"Códigos válidos encontrados na coluna '{coluna_codigos}' no arquivo '{path}':")
                        print(df.loc[codigos_encontrados, coluna_codigos].unique())
                        colunas_a_manter.append(coluna_codigos)
                    else:
                        print(f"Nenhum código válido encontrado na coluna '{coluna_codigos}' no arquivo '{path}'. A coluna não será incluída no arquivo final.")
                else:
                    print(f"A coluna '{coluna_codigos}' não foi encontrada no arquivo '{path}'.")
            
            df_filtrado = df[colunas_a_manter].copy()
            
            # Recalcula a coluna NM_COVA sem alterar NM_FILA original:
            # Cria uma coluna auxiliar para identificar mudanças contíguas em NM_FILA.
            df_filtrado['grupo'] = (df_filtrado['NM_FILA'] != df_filtrado['NM_FILA'].shift()).cumsum()
            # Para cada grupo contíguo, NM_COVA recebe a contagem sequencial a partir de 1.
            df_filtrado['NM_COVA'] = df_filtrado.groupby('grupo').cumcount() + 1
            # Remove a coluna auxiliar
            df_filtrado.drop(columns=['grupo'], inplace=True)
            
            # Tratamento da coluna CD_TALHAO:
            # Converte o valor para string, preenche com zeros à esquerda se tiver menos de 3 dígitos
            # e mantém somente os últimos 3 caracteres se tiver mais de 3 dígitos.
            df_filtrado['CD_TALHAO'] = df_filtrado['CD_TALHAO'].astype(str).apply(lambda x: x.zfill(3)[-3:])
            
            # Cria a coluna EQUIPES, extraindo a identificação da equipe do nome do arquivo.
            # Exemplo: se o nome do arquivo contiver "EQ_01", EQUIPES será "ep_01".
            filename = os.path.basename(path)
            match = re.search(r'EQ_(\d+)', filename, re.IGNORECASE)
            if match:
                equipe = f"ep_{match.group(1).zfill(2)}"
            else:
                equipe = "ep_unknown"
            df_filtrado['EQUIPES'] = equipe
            
            # Ajusta a coluna NM_COVA conforme a presença de 'L' nas colunas CD_01, CD_02 ou CD_03
            for col in ['CD_01', 'CD_02', 'CD_03']:
                if col in df_filtrado.columns and df_filtrado[col].notna().any():
                    df_filtrado['NM_COVA'] = df_filtrado.apply(
                        lambda row: row['NM_COVA'] if row[col] != 'L' else row['NM_COVA'] - 1,
                        axis=1
                    )
            
            lista_df.append(df_filtrado)
        
        # Se ao menos um arquivo foi processado, une os dados em um único DataFrame
        if lista_df:
            df_final = pd.concat(lista_df, ignore_index=True)
            # Salva o DataFrame final em uma única planilha Excel
            # O arquivo será salvo na pasta do primeiro arquivo processado
            novo_arquivo_excel = os.path.join(os.path.dirname(paths[0]), 'Base_dados_unificadas_modificado.xlsx')
            df_final.to_excel(novo_arquivo_excel, index=False)
            print(f"Todos os dados foram unificados e salvos como '{novo_arquivo_excel}'.")
        else:
            print("Nenhum arquivo foi processado com sucesso.")

# Exemplo de uso:
otimizador = OtimizadorIFQ6()
arquivos = [
    '/content/Base_dados_EQ_01.xlsx',
    '/content/Base_dados_EQ_02.xlsx',
    '/content/Base_dados_EQ_03.xlsx'
]
otimizador.validacao(arquivos, ['cd_02', 'cd_03'])
